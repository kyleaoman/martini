{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this short tutorial we will install and use [MARTINI](https://martini.readthedocs.io/en/latest/), an analysis package for creating mock HI-data cubes similar to radio interferometer data, written by Kyle Oman (kyle.a.oman@durham.ac.uk). This example uses the input from the [IllustrisTNG](https://ui.adsabs.harvard.edu/abs/2018MNRAS.473.4077P/abstract) simulations. The data are publicly available and hosted at [tng-project.org](https://www.tng-project.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial can be run either on the [TNG JupyterLab environment](https://www.tng-project.org/data/lab/), or on any system with internet access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MARTINI](https://github.com/kyleaoman/martini/raw/main/martini_banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MARTINI is a modular package for the creation of synthetic resolved HI line observations (data cubes) of smoothed-particle hydrodynamics simulations of galaxies. The various aspects of the mock-observing process are divided logically into sub-modules handling the data cube, source, beam, noise, spectral model and SPH kernel. MARTINI is object-oriented: each sub-module provides a class (or classes) which can be configured as desired. For most sub-modules, base classes are provided to allow for straightforward customization. Instances of each sub-module class are given as parameters to the Martini class; a mock observation is then constructed by calling a handful of functions to execute the desired steps in the mock-observing process.\n",
    "\n",
    "The MARTINI documentation is [hosted on ReadTheDocs](https://martini.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MARTINI requires `python3` version `3.7` or higher.\n",
    "\n",
    "The following command will use `pip` to download and install [MARTINI from pypi](https://pypi.org/project/astromartini/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/koman/code/martini\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (from astromartini==2.0.1) (1.22.4)\n",
      "Requirement already satisfied: scipy in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (from astromartini==2.0.1) (1.8.0)\n",
      "Requirement already satisfied: astropy in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (from astromartini==2.0.1) (5.0.1)\n",
      "Requirement already satisfied: tqdm in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (from astromartini==2.0.1) (4.64.1)\n",
      "Requirement already satisfied: pyerfa>=2.0 in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (from astropy->astromartini==2.0.1) (2.0.0.1)\n",
      "Requirement already satisfied: PyYAML>=3.13 in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (from astropy->astromartini==2.0.1) (6.0)\n",
      "Requirement already satisfied: packaging>=19.0 in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (from astropy->astromartini==2.0.1) (23.0)\n",
      "Building wheels for collected packages: astromartini\n",
      "  Building wheel for astromartini (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for astromartini: filename=astromartini-2.0.1-py3-none-any.whl size=73303 sha256=b2ec0975b1f06269a28a77a1bbd47f0fd1e018acd91f15f2805e9759c5f1e9ae\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9h0oosns/wheels/ad/39/16/b54749e0fb41d3bcf02c04c583e493a4f51a3272aabff0b0ed\n",
      "Successfully built astromartini\n",
      "Installing collected packages: astromartini\n",
      "  Attempting uninstall: astromartini\n",
      "    Found existing installation: astromartini 2.0.1\n",
      "    Uninstalling astromartini-2.0.1:\n",
      "      Successfully uninstalled astromartini-2.0.1\n",
      "Successfully installed astromartini-2.0.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "#!{sys.executable} -m pip install astromartini[tngsource]==2.0.1\n",
    "!{sys.executable} -m pip install /home/koman/code/martini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not have superuser permissions or use a virtual environment, you may wish to add the --user flag.\n",
    "With this command required dependencies will be fetched and installed automatically. Watch for error messages during installation. For greater control you may also install the dependencies by hand. These are: numpy, astropy, scipy, h5py, six and requests.\n",
    "\n",
    "We'll also install matplotlib, used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (from matplotlib) (4.29.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (from matplotlib) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/koman/.miniconda3/envs/koman/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we can `import martini`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import martini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this produces errors, you may need to restart the Python kernel of this notebook so that it sees the recently installed packages (Kernel -> Restart in the menubar).\n",
    "\n",
    "We can run MARTINI's built-in demo to check that all of the basic functionality works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source module contained 500 particles with total HI mass of 5.00e+09 solMass.\n",
      "Pruned particles that will not contribute to data cube, 500 particles remaining with total HI mass of 5.00e+09 solMass.\n",
      "Inserting source in cube.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████▎                          | 6603/23716 [00:10<00:28, 596.79it/s]"
     ]
    }
   ],
   "source": [
    "from martini import demo\n",
    "\n",
    "demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "When run successfully, this will make a mock observation of a very simple analytic disc model and write some output to the working directory. Rather than inspect this toy model, let's look at a \"real\" simulation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TNG Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TNGSource` module in MARTINI is designed to run on the IllustrisTNG [JupyterLab](https://www.tng-project.org/data/lab/), or in a standalone mode. If you are running on the TNG JupyterLab then the simulations are stored locally on disk and will be detected and used. Otherwise, the `TNGSource` module will use the TNG [web API](https://www.tng-project.org/data/docs/api/) to download the particles for the galaxy of interest. If running in standalone mode, an API key for the TNG web API is required. You must first [register](https://www.tng-project.org/users/register/) for an account. Once you are registered, your API key can be found [here](https://www.tng-project.org/users/profile/). Enter your API key using the following cell (if you are running this notebook on the TNG JupyterLab, you may leave it blank):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "api_key = getpass(\"TNG web API key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose a galaxy of interest by selection a [simulation](https://www.tng-project.org/data/docs/background/), a [snapshot](http://www.tng-project.org/data/docs/specifications/#sec1a) and a subhalo ID. One way to search for a subhalo ID is to use [this tool](https://www.tng-project.org/data/search/) - the `ID` column in search results contains subhalo IDs. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation = \"TNG100-1\"\n",
    "snapshot = 99\n",
    "subhalo_id = 400547  # a central subhalo with 218 < Vmax < 220, and SFR > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TNG Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import some modules from MARTINI, and the units module from astropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from martini.sources import TNGSource\n",
    "from martini import DataCube, Martini\n",
    "from martini.beams import GaussianBeam\n",
    "from martini.noise import GaussianNoise\n",
    "from martini.spectral_models import GaussianSpectrum\n",
    "from martini.sph_kernels import (\n",
    "    AdaptiveKernel,\n",
    "    GaussianKernel,\n",
    "    CubicSplineKernel,\n",
    "    DiracDeltaKernel,\n",
    ")\n",
    "import astropy.units as U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different martini sub-modules need to be initialized, see the [full documentation](https://kyleaoman.github.io/martini/build/html/) for details of all configuration options. A few suggested best-practices specific to TNG are outlined below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOURCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rotation configuration takes an inclination (here 60deg) and\n",
    "rotation about the pole (here 90deg, relative to an arbitrary reference direction). The code attempts to\n",
    "automatically align the galactic disk in the y-z plane by aligning\n",
    "the angular momentum along the x-axis. The polar rotation is then\n",
    "applied, and finally the disc inclined by a rotation around the\n",
    "y-axis (the line of sight is along the x-axis). The automatic\n",
    "alignment will work for typical reasonably isolated discs, but will\n",
    "struggle when companions are present, when the angular momentum axis\n",
    "is a poor tracer of the disc plane, and especially for satellites. If\n",
    "finer control of the orientation is needed, derive the transformation\n",
    "from the simulation box coordinates to the desired coordinates for\n",
    "the 'observation', keeping in mind that the line of sight is along\n",
    "the x-axis. This rotation matrix can then be passed to as\n",
    "`rotation={'rotmat': np.eye(3)}` (here the identity rotation matrix used as a place holder). A common problem in this case is deriving the inverse\n",
    "transform instead of the forward transform, if unexpected results are\n",
    "obtained, first try passing the transpose of the rotation matrix.\n",
    "\n",
    "Notice that your API key must be provided unless you are using `TNGSource` on the TNG JupyterLab (if you provide it anyways in that case, it will simply be ignored).\n",
    "\n",
    "Any downloaded data can be cached using the `cutout_dir` parameter to specify a directory, if a cache for the requested galaxy is found it will be used instead of re-downloading the data. If running on the TNG JupyterLab environment, this parameter is ignored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = TNGSource(\n",
    "    simulation,\n",
    "    snapshot,\n",
    "    subhalo_id,\n",
    "    api_key=api_key,\n",
    "    cutout_dir=\".\",\n",
    "    distance=4 * U.Mpc,\n",
    "    rotation={\"L_coords\": (60 * U.deg, 0.0 * U.deg)},\n",
    "    ra=0.0 * U.deg,\n",
    "    dec=0.0 * U.deg,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DATACUBE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is usually advisable to set the centre of the cube to track the\n",
    "centre of the source, as illustrated below. Note that the source\n",
    "systemic velocity is set according to the distance, peculiar velocity, and Hubble's law.\n",
    "These values can instead be set explicitly, if desired. A datacube\n",
    "with 128x128 pixels usually takes a few minutes, depending on the number of particles. 1024x1024 can take\n",
    "several hours. The number of channels has less influence on the\n",
    "runtime. Most of the runtime is spent when `M.insert_source_in_cube` is\n",
    "called below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube = DataCube(\n",
    "    n_px_x=384,\n",
    "    n_px_y=384,\n",
    "    n_channels=50,\n",
    "    px_size=10.0 * U.arcsec,\n",
    "    channel_width=16.0 * U.km * U.s**-1,\n",
    "    velocity_centre=source.vsys,\n",
    "    ra=source.ra,\n",
    "    dec=source.dec,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is usually advisable to set the beam size to be ~3x the pixel\n",
    "size. Note that the data cube is padded according to the size of the\n",
    "beam, this usually results in the number of pixel rows printed in the\n",
    "progress messages to differ from the requested dimensions. The\n",
    "padding is required for accurate convolution with the beam, but\n",
    "contains incorrect values after convolution and is discarded to\n",
    "produce the final data cube of the requested size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam = GaussianBeam(\n",
    "    bmaj=30.0 * U.arcsec, bmin=30.0 * U.arcsec, bpa=0.0 * U.deg, truncate=3.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### NOISE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noise is normally added before convolution with the beam (as\n",
    "below in this example). The rms value passed is that corresponding to the desired noise level in the final data cube, in Jy/beam or equivalent units. To obtain consistent random realisations each time the code is run, we provide a random seed (integer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = GaussianNoise(\n",
    "    rms=3.0e-8 * U.Jy * U.beam**-1,\n",
    "    seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPECTRAL MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `thermal` mode estimates the HI line width for each particle based on its properties (temperature, etc.). The 'subgrid' velocity dispersion can also be fixed to a constant value, e.g. `sigma=7 * U.km / U.s`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_model = GaussianSpectrum(sigma=\"thermal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPH KERNEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since IllustrisTNG uses a moving mesh hydrodynamics solver (Arepo),\n",
    "there are no formal SPH smoothing lengths and no specified kernel.\n",
    "However, approximate smoothing lengths can be derived from the cell\n",
    "volumes and densities, so a reasonable approximation is to use these for imaging. \n",
    "\n",
    "MARTINI's kernel module implementations use approximations which can break down when the particle smoothing lengths are small compared to the size of the pixels (at the distance of the source). If the approximation in question is not accurate enough, MARTINI will report an error. In this case it might be appropriate to choose another SPH kernel module. Some rules of thumb for making this choice:\n",
    " - For very low resolution observations (distant source and few pixels), use the `DiracDeltaKernel`.\n",
    " - For high resolution observations (nearby source and many pixels), preferably use the kernel matching that used to run the simulation. In the case of Arepo, which uses a moving mesh rather than SPH, the `CubicSplineKernel` is suggested.\n",
    " - The `GaussianKernel` with `truncate=6` has the least stringent requirements for accuracy, but is significantly slower because of its large extent and so should not be used as a first choice.\n",
    " - For intermediate resolution observations (when the kernel size is similar to the pixel size), it may be difficult to find a kernel which does not raise an error. In this case, you may consider using the AdaptiveKernel. This module accepts a list of other kernels in order of decreasing priority. The first which is sufficiently accurate is used on a per-particle basis. This usage is illustrated in the example below - first the `CubicSplineKernel` is tried for particles with long smoothing lengths relative to the pixel scale, then the `DiracDeltaKernel` is used for particles with small smoothing lengths relative to the pixels, and finally falling back on the `GaussianKernel` for intermediate smoothing lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sph_kernel = AdaptiveKernel(\n",
    "    (CubicSplineKernel(), DiracDeltaKernel(), GaussianKernel(truncate=6))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MARTINI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set up the configuration, and do the actual run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Martini(\n",
    "    source=source,\n",
    "    datacube=datacube,\n",
    "    beam=beam,\n",
    "    noise=noise,\n",
    "    spectral_model=spectral_model,\n",
    "    sph_kernel=sph_kernel,\n",
    ")\n",
    "M.insert_source_in_cube()\n",
    "M.add_noise()\n",
    "M.convolve_beam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that the number of pixels in the progress counter differs from the number defined in the DataCube module. This is because convolution with the beam requires some padding, which is ultimately filled with nonsense and discarded.\n",
    "\n",
    "To write the results: two output formats are available, depending on preference. Both\n",
    "formats are self-documenting, via FITS header keywords and HDF5\n",
    "attributes, respectively. For HDF5 output, the beam image is included\n",
    "in the same file. (If you do not have h5py installed, comment out the call to `write_hdf5`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.write_fits(\"tngdemo.fits\", channels=\"velocity\")\n",
    "M.write_beam_fits(\"tngdemo_beam.fits\", channels=\"velocity\")\n",
    "M.write_hdf5(\"tngdemo.hdf5\", channels=\"velocity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the HDF5 that MARTINI produced and take a quick look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File(\"tngdemo.hdf5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FluxCube = f[\"FluxCube\"][()]\n",
    "vch = f[\"channel_mids\"][()] / 1e3 - source.distance.to(U.Mpc).value * 70  # m/s to km/s\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FluxCube.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine one of the velocity channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "plt.imshow(FluxCube[:, :, 15].T, cmap=\"Greys\", aspect=1.0, origin=\"lower\")\n",
    "ax.autoscale(False)\n",
    "ax.set_xlabel(\"x [px = arcsec/{:.0f}]\".format(datacube.px_size.to(U.arcsec).value))\n",
    "ax.set_ylabel(\"y [px = arcsec/{:.0f}]\".format(datacube.px_size.to(U.arcsec).value))\n",
    "plt.colorbar(label=\"Flux [Jy/beam]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And do a quick plot of the first three moments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.seterr(all=\"ignore\")\n",
    "fig = plt.figure(figsize=(16, 5))\n",
    "sp1 = fig.add_subplot(1, 3, 1)\n",
    "sp2 = fig.add_subplot(1, 3, 2)\n",
    "sp3 = fig.add_subplot(1, 3, 3)\n",
    "rms = np.std(FluxCube[:16, :16])  # noise in a corner patch where there is little signal\n",
    "clip = np.where(FluxCube > 5 * rms, 1, 0)\n",
    "mom0 = np.sum(FluxCube, axis=-1)\n",
    "mask = np.where(mom0 > 0.05, 1, np.nan)\n",
    "mom1 = np.sum(FluxCube * clip * vch, axis=-1) / mom0\n",
    "mom2 = (\n",
    "    np.sqrt(np.sum(FluxCube * clip * np.power(vch - mom1[..., np.newaxis], 2), axis=-1))\n",
    "    / mom0\n",
    ")\n",
    "im1 = sp1.imshow(mom0.T, cmap=\"Greys\", aspect=1.0, origin=\"lower\")\n",
    "plt.colorbar(im1, ax=sp1, label=\"mom0 [Jy/beam]\")\n",
    "im2 = sp2.imshow((mom1 * mask).T, cmap=\"RdBu\", aspect=1.0, origin=\"lower\")\n",
    "plt.colorbar(im2, ax=sp2, label=\"mom1 [km/s]\")\n",
    "im3 = sp3.imshow(\n",
    "    (mom2 * mask).T, cmap=\"magma\", aspect=1.0, origin=\"lower\", vmin=0, vmax=300\n",
    ")\n",
    "plt.colorbar(im3, ax=sp3, label=\"mom2 [km/s]\")\n",
    "for sp in sp1, sp2, sp3:\n",
    "    sp.set_xlabel(\"x [px = arcsec/10]\")\n",
    "    sp.set_ylabel(\"y [px = arcsec/10]\")\n",
    "plt.subplots_adjust(wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This galaxy clearly has a very nice spiral morphology in HI, has a rotation-dominated velocity field, and is interacting with a companion. The alignment of the disc looks as expected - the inclination looks to be about 60 degrees, and the position angle is horizontal in the figure - in this case the automated orientation function has performed well, though it should never be assumed that this will always be the case!\n",
    "\n",
    "For complete documentation, more usage examples, and further information, please take a look at the [MARTINI webpage](https://kyleaoman.github.io/martini)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
