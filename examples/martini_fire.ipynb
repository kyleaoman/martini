{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this short tutorial we will install and use [MARTINI](https://martini.readthedocs.io/en/latest/), an analysis package for creating mock HI-data cubes similar to radio interferometer data, written by Kyle Oman (kyle.a.oman@durham.ac.uk). This example uses input from the [FIRE-2](https://ui.adsabs.harvard.edu/abs/2018MNRAS.480..800H/abstract) simulations. The data are publicly available and hosted at [flathub.flatironinstitute.org/fire](https://flathub.flatironinstitute.org/fire)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MARTINI](https://github.com/kyleaoman/martini/raw/main/martini_banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MARTINI is a modular package for the creation of synthetic resolved HI line observations (data cubes) of smoothed-particle hydrodynamics simulations of galaxies. The various aspects of the mock-observing process are divided logically into sub-modules handling the data cube, source, beam, noise, spectral model and SPH kernel. MARTINI is object-oriented: each sub-module provides a class (or classes) which can be configured as desired. For most sub-modules, base classes are provided to allow for straightforward customization. Instances of each sub-module class are given as parameters to the Martini class; a mock observation is then constructed by calling a handful of functions to execute the desired steps in the mock-observing process.\n",
    "\n",
    "This tutorial focuses on particulars related to working with the FIRE simulations. More general information is available in the MARTINI documentation, [hosted on ReadTheDocs](https://martini.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MARTINI requires `python3` version `3.8` or higher.\n",
    "\n",
    "The following command will use `pip` to download and install [MARTINI from pypi](https://pypi.org/project/astromartini/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# WAITING ON A. WETZEL TO RELEASE DEPENDENCIES AS PACKAGE\n",
    "# !{sys.executable} -m pip install \"astromartini[firesource]==2.1.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not have superuser permissions or use a virtual environment, you may wish to add the --user flag.\n",
    "With this command required dependencies will be fetched and installed automatically. Watch for error messages during installation. For greater control you may also install the dependencies by hand. These are: numpy, astropy, scipy and h5py.\n",
    "\n",
    "We'll also install a few other packages used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install requests matplotlib beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell may be needed in some cases to display figures below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we can `import martini`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import martini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this produces errors, you may need to restart the Python kernel of this notebook so that it sees the recently installed packages (Kernel -> Restart in the menubar).\n",
    "\n",
    "We can run MARTINI's built-in demo to check that all of the basic functionality works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from martini import demo\n",
    "\n",
    "demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "When run successfully, this will make a mock observation of a very simple analytic disc model and write some output to the working directory. Rather than inspect this toy model, let's look at a \"real\" simulation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIRE Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses data from the FIRE-2 simulations. These data are hosted at [https://flathub.flatironinstitute.org/fire](https://flathub.flatironinstitute.org/fire).\n",
    "\n",
    "In this example, we will use the [`m11e_res7100`](https://users.flatironinstitute.org/~chayward/fire2_public_release/core/m11e_res7100) simulation (80 GB). The following cell will download it directly, but note that a [Globus](https://www.globus.org/) endpoint is also provided (see [FlatHUB page](https://flathub.flatironinstitute.org/fire) for details) that can make transfers substantially faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import re\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import bs4\n",
    "\n",
    "data_url = \"https://users.flatironinstitute.org/~chayward/fire2_public_release/core/\"\n",
    "simulation_directory = \"m11e_res7100/\"\n",
    "\n",
    "\n",
    "def direct_download(url, fname):\n",
    "    with requests.get(url) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(fname, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "\n",
    "def chunked_download(url, fname):\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        total_size_in_bytes = int(r.headers.get(\"content-length\", 0))\n",
    "        chunk_size = 8192\n",
    "        progress_bar = tqdm(total=total_size_in_bytes, unit=\"iB\", unit_scale=True)\n",
    "        with open(fname, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                progress_bar.update(len(chunk))\n",
    "                f.write(chunk)\n",
    "    return\n",
    "\n",
    "\n",
    "def directory_download(url_base, directory, chunked_if_larger_than=1024 * 1024 * 10):\n",
    "    dir_url = urllib.parse.urljoin(url_base, directory)\n",
    "    print(directory)\n",
    "    os.mkdir(directory)\n",
    "    r = requests.get(dir_url)\n",
    "    data = bs4.BeautifulSoup(r.text, \"html.parser\")\n",
    "    for link in data.find_all(\"a\"):\n",
    "        link_url = urllib.parse.urljoin(dir_url, link[\"href\"])\n",
    "        if \"..\" in link[\"href\"]:  # parent directory, skip\n",
    "            continue\n",
    "        elif \".\" in link[\"href\"]:  # a file, download\n",
    "            target_file = urllib.parse.urljoin(directory, link[\"href\"])\n",
    "            with requests.head(link_url) as h:\n",
    "                h.raise_for_status()\n",
    "                total_size_in_bytes = int(h.headers.get(\"content-length\", 0))\n",
    "                print(target_file)\n",
    "                if total_size_in_bytes > chunked_if_larger_than:\n",
    "                    chunked_download(link_url, target_file)\n",
    "                else:\n",
    "                    direct_download(link_url, target_file)\n",
    "        else:  # a directory, recurse\n",
    "            directory_download(url_base, urllib.parse.urljoin(directory, link[\"href\"]))\n",
    "\n",
    "\n",
    "if os.path.isdir(simulation_directory):\n",
    "    print(\"Found directory matching simulation_directory locally, skipping download.\")\n",
    "else:\n",
    "    directory_download(data_url, simulation_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have downloaded the data manually, edit this cell to specify the location of the base directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_directory = (\n",
    "    simulation_directory  # e.g. simulation_directory = \"/path/to/m11e_res7100/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The i/o tools for FIRE simulations allow a few ways of defining a snapshot, by its `\"index\"`, `\"redshift\"` or `\"scalefactor\"`. Here we'll use the `\"redshift\"` method and specify redshift `0`; the i/o tools will automatically select the closest snapshot to z=0. Since the FIRE suite is a set of zoom simulations (at least those in the FIRE-2 [public data release](https://flathub.flatironinstitute.org/fire)), the galaxy of interest is usually the first in the catalogue, corresponding to `host_number = 1`. Subsequent galaxies in the catalogue can be selected by increasing this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = (\"redshift\", 0)\n",
    "host_number = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIRE Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import some modules from Martini, and the units module from astropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from martini.sources import FIRESource\n",
    "from martini import DataCube, Martini\n",
    "from martini.beams import GaussianBeam\n",
    "from martini.noise import GaussianNoise\n",
    "from martini.spectral_models import GaussianSpectrum\n",
    "from martini.sph_kernels import CubicSplineKernel\n",
    "import astropy.units as U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different martini sub-modules need to be initialized, \n",
    "see the [full documentation](https://martini.readthedocs.io/en/latest/) for details of all configuration options. A few suggested best-practices specific to FIRE are outlined below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOURCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FIRESource` module is built around the i/o tools for the FIRE simulations, which are built assuming that the target object in a zoom simulation is an object of interest. The default (and only) behaviour is to read in all of the particles of a given type in the snapshot. Initializing the source module will therefore have a memory usage similar to the size of the gas particle arrays in the snapshot (in this case about ?? GB). The memory footprint can be reduced by reducing precision to 32-bit floats with `convert_float32=True`.\n",
    "\n",
    "Galaxy positions and velocities are assigned by default using a \"shrinking spheres\" algorithm weighted by the particle masses (`assign_hosts=\"mass\"`), but other schemes are also available (potential-weighted with `assign_hosts=\"potential\"`, metallicity-weighted with `assign_hosts=\"massfraction.metals\"`, based on smoothed position across snapshots with `assign_hosts=\"track\"`, read directly from the Rockstar halo finder catalogues with `assign_hosts=\"halo\"`; setting `assign_hosts=True` will attempt to find a sensible default by first trying `\"track\"`, then `\"mass\"`).\n",
    "\n",
    "The `FIRESource` assumes the molecular gas partitioning scheme described in [Orr et al. (2018)](https://ui.adsabs.harvard.edu/abs/2018MNRAS.478.3653O/abstract), Appendix B.\n",
    "\n",
    "The i/o tools print some messages as data is read, at present there does not seem to be an option to silence these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = FIRESource(\n",
    "    simulation_directory=simulation_directory,\n",
    "    snapshot=snapshot,\n",
    "    host_number=host_number,\n",
    "    assign_hosts=\"mass\",\n",
    "    convert_float32=False,\n",
    "    distance=5.0 * U.Mpc,\n",
    "    vpeculiar=0 * U.km / U.s,\n",
    "    rotation={\"rotmat\": np.eye(3)},\n",
    "    ra=0.0 * U.deg,\n",
    "    dec=0.0 * U.deg,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rotation argument above has been set to the identity matrix, so the source has the (random) orientation that it has within the simulation volume. The source class includes a function to make a quick plot to get an idea of the source's appearance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_fig_unrotated = source.preview(title=\"unrotated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preview function defaults to apertures in position and velocity that enclose all particles in the source (and therefore the entire zoom simulation), so this preview emphasizes the diffuse circumgalactic and intergalactic gas. The apertures can be set manually using the `lim` and `vlim` keywords to set the maximum absolute offsets in position and velocity relative to the source centre to be plotted. For example, restricting the aperture to 50kpc and 300km/s makes the disc more clearly visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_fig_unrotated_zoom = source.preview(\n",
    "    title=\"unrotated, zoomed-in\",\n",
    "    lim=50 * U.kpc,\n",
    "    vlim=300 * U.km / U.s,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This randomly-oriented viewing angle seems to be moderately inclined with respect to the disc. The source can be rotated to a different orientation. MARTINI's tool for quick/approximate manipulation of the orientation of the source aligns the source based on its angular momentum vector (\"L\"), for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source.rotate(L_coords=(60 * U.deg, 90 * U.deg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rotation configuration takes an inclination (here 60deg) and rotation about the pole (here 90deg, relative to an arbitrary reference direction). The code attempts to\n",
    "automatically align the galactic disk in the y-z plane by aligning\n",
    "the angular momentum along the x-axis. The polar rotation is then\n",
    "applied, and finally the disc inclined by a rotation around the\n",
    "y-axis (the line of sight is along the x-axis). The automatic\n",
    "alignment will work for typical reasonably isolated discs (no other galaxies with HI in the zoom region), but will\n",
    "struggle when companions are present, when the angular momentum axis\n",
    "is a poor tracer of the disc plane, and especially for satellites or galaxies in pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_fig_rotated_zoomed_in = source.preview(\n",
    "    title=\"rotated, zoomed-in\",\n",
    "    lim=50 * U.kpc,\n",
    "    vlim=300 * U.km / U.s,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If finer control of the orientation is needed, derive the transformation from the simulation box coordinates (see [the documentation](https://martini.readthedocs.io/en/latest/) for examples) to the desired coordinates for the 'observation', keeping in mind that the line of sight is along the x-axis. This rotation matrix can then be passed to the rotate function as `rotmat=np.eye(3)` (here the identity rotation matrix used as a place holder). The rotation can also be provided when the source is initialized by using the `rotation` keyword argument.\n",
    "\n",
    "A common problem is deriving the inverse transform instead of the forward transform, if unexpected results are obtained, first try passing the transpose of the rotation matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATACUBE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is usually advisable to set the centre of the cube to track the\n",
    "centre of the source, as illustrated below. Note that the source\n",
    "systemic velocity is set according to the distance, peculiar velocity, and Hubble's law.\n",
    "These values can instead be set explicitly, if desired. A datacube\n",
    "with 128x128 pixels usually takes a few minutes, depending on the number of particles. 1024x1024 can take\n",
    "several hours. The number of channels has less influence on the\n",
    "runtime. Most of the runtime is spent when `M.insert_source_in_cube` is\n",
    "called below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube = DataCube(\n",
    "    n_px_x=384,\n",
    "    n_px_y=384,\n",
    "    n_channels=50,\n",
    "    px_size=10.0 * U.arcsec,\n",
    "    channel_width=5.0 * U.km * U.s**-1,\n",
    "    velocity_centre=source.vsys,\n",
    "    ra=source.ra,\n",
    "    dec=source.dec,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is usually advisable to set the beam size to be ~3x the pixel\n",
    "size. Note that the data cube is padded according to the size of the\n",
    "beam, this usually results in the number of pixel rows printed in the\n",
    "progress messages to differ from the requested dimensions. The\n",
    "padding is required for accurate convolution with the beam, but\n",
    "contains incorrect values after convolution and is discarded to\n",
    "produce the final data cube of the requested size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam = GaussianBeam(\n",
    "    bmaj=30.0 * U.arcsec,\n",
    "    bmin=30.0 * U.arcsec,\n",
    "    bpa=0.0 * U.deg,\n",
    "    truncate=3.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### NOISE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noise is normally added before convolution with the beam (as\n",
    "below in this example). The rms value passed is that corresponding to the desired noise level in the final data cube, in Jy/beam or equivalent units. To obtain consistent random realisations each time the code is run, we provide a random seed (integer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = GaussianNoise(\n",
    "    rms=3.0e-8 * U.Jy * U.beam**-1,\n",
    "    seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SPECTRAL MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `thermal` mode estimates the HI line width for each particle based on its properties (temperature, etc.). The 'subgrid' velocity dispersion can also be fixed to a constant value, e.g. `sigma=7 * U.km / U.s`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spectral_model = GaussianSpectrum(sigma=\"thermal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation of the spectra (that will happen when the `Martini` module is initialized below) can be done in parallel by providing a keyword argument `ncpu=N`, where `N` is the number of CPUs to use. However, the details of the implementation mean that for small numbers of particles running in parallel tends to slow down the calculation, so turning this on should be done with care. Significant speedups can be expected when the particle count is very large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPH KERNEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FIRE simulations are meshless finite mass (MFM), not smoothed particle hydrodynamics (SPH) simulations. MARTINI is strictly speaking designed for SPH simulations, but can still provide a good approximation of non-SPH simulations by representing mesh cells as SPH particles assuming their centroids and characteristic smoothing lengths. The MFM scheme in FIRE uses a cubic spline kernel function (although this is not an SPH kernel), so we may as well use MARTINI's `CubicSplineKernel` module for the approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sph_kernel = CubicSplineKernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MARTINI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set up the configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Martini(\n",
    "    source=source,\n",
    "    datacube=datacube,\n",
    "    beam=beam,\n",
    "    noise=noise,\n",
    "    spectral_model=spectral_model,\n",
    "    sph_kernel=sph_kernel,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to previewing the source, we can make a preview here. Now the extent of the datacube is overlaid with a red box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.preview(\n",
    "    point_scaling=\"fixed\", vlim=180 * U.km / U.s\n",
    ")  # can experiment with parameters here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main source insertion loop, that is the most computationally demanding step, can be run in parallel if the `multiprocess` package is installed (not to be confused with `multiprocessing`, which is normally included with python!). Edit the cell below to use more than 1 CPU core if this package is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbmake": {
     "post_cell_execute": [
      "ncpu = 8"
     ]
    }
   },
   "outputs": [],
   "source": [
    "ncpu = 1  # can be >1 if multiprocess package is installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're happy with the preview, we're ready to call the functions to make the actual mock observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.insert_source_in_cube(ncpu=ncpu)\n",
    "M.add_noise()\n",
    "M.convolve_beam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that the number of pixels in the progress counter differs from the number defined in the DataCube module. This is because convolution with the beam requires some padding, which is ultimately filled with nonsense and discarded.\n",
    "\n",
    "To write the results: two output formats are available, depending on preference. Both\n",
    "formats are self-documenting, via FITS header keywords and HDF5\n",
    "attributes, respectively. For HDF5 output, the beam image is included\n",
    "in the same file. (If you do not have h5py installed, comment out the call to `write_hdf5`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.write_fits(\"fire_martini_demo.fits\")\n",
    "M.write_beam_fits(\"fire_martini_demo_beam.fits\")\n",
    "M.write_hdf5(\"fire_martini_demo.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the results (FITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the FITS file that MARTINI produced and take a quick look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "with fits.open(\"fire_martini_demo.fits\") as f:\n",
    "    cube_wcs = WCS(f[0].header)\n",
    "    flux_cube = f[0].data * U.Unit(f[0].header[\"BUNIT\"])\n",
    "    n_channels = cube_wcs.pixel_shape[cube_wcs.wcs.spec]\n",
    "    vch = np.array(cube_wcs.sub(axes=[3]).all_pix2world(np.arange(n_channels), 0))[\n",
    "        0\n",
    "    ] * U.Unit(cube_wcs.world_axis_units[cube_wcs.wcs.spec])\n",
    "    vch = vch - source.vsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_cube.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine one of the velocity channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.clf()\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\", projection=cube_wcs.celestial)\n",
    "\n",
    "# choose units for plotting, not necessarily the units data are stored in:\n",
    "flux_unit = U.Jy / U.beam\n",
    "\n",
    "plt.imshow(flux_cube[27, ...].to_value(flux_unit), cmap=\"Greys\")\n",
    "plt.xlabel(\"RA\")\n",
    "plt.ylabel(\"Dec\")\n",
    "plt.colorbar(label=f\"Flux [{flux_unit}]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And do a quick plot of the first three moments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# choose plotting units\n",
    "mom0_unit = U.Jy / U.beam\n",
    "mom1_unit = U.km / U.s\n",
    "mom2_unit = U.km / U.s\n",
    "\n",
    "rms = np.std(\n",
    "    flux_cube[:, :20, :20]\n",
    ")  # noise in a corner patch where there is little signal\n",
    "clip = np.where(flux_cube > 5 * rms, 1, 0)\n",
    "np.seterr(all=\"ignore\")\n",
    "fig = plt.figure(figsize=(16, 5))\n",
    "plt.clf()\n",
    "sp1 = fig.add_subplot(1, 3, 1, aspect=\"equal\", projection=cube_wcs.celestial)\n",
    "sp2 = fig.add_subplot(1, 3, 2, aspect=\"equal\", projection=cube_wcs.celestial)\n",
    "sp3 = fig.add_subplot(1, 3, 3, aspect=\"equal\", projection=cube_wcs.celestial)\n",
    "mom0 = np.sum(flux_cube, axis=0)\n",
    "mask = np.where(mom0 > 0.002 * U.Jy / U.beam, 1, np.nan)\n",
    "mom1 = np.sum(flux_cube * clip * vch[:, np.newaxis, np.newaxis], axis=0) / mom0\n",
    "mom2 = np.sqrt(\n",
    "    np.sum(\n",
    "        flux_cube\n",
    "        * clip\n",
    "        * np.power(vch[:, np.newaxis, np.newaxis] - mom1[np.newaxis], 2),\n",
    "        axis=0,\n",
    "    )\n",
    "    / mom0\n",
    ")\n",
    "im1 = sp1.imshow(mom0.to_value(mom0_unit), cmap=\"Greys\")\n",
    "plt.colorbar(im1, ax=sp1, label=f\"mom0 [{mom0_unit}]\")\n",
    "im2 = sp2.imshow(\n",
    "    (mom1 * mask).to_value(mom1_unit),\n",
    "    cmap=\"RdBu_r\",\n",
    "    vmin=-np.nanmax(np.abs(mom1 * mask)).to_value(mom1_unit),\n",
    "    vmax=np.nanmax(np.abs(mom1 * mask)).to_value(mom1_unit),\n",
    ")\n",
    "plt.colorbar(im2, ax=sp2, label=f\"mom1 [{mom1_unit}]\")\n",
    "im3 = sp3.imshow(\n",
    "    (mom2 * mask).to_value(mom2_unit),\n",
    "    cmap=\"magma\",\n",
    ")\n",
    "plt.colorbar(im3, ax=sp3, label=f\"mom2 [{mom2_unit}]\")\n",
    "for sp in sp1, sp2, sp3:\n",
    "    sp.set_xlabel(\"RA\")\n",
    "    sp.set_ylabel(\"Dec\")\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This galaxy has a strongly disturbed morphology, but does display clear signs of rotation. The alignment of the disc, such as it is, looks as expected - the inclination is plausibly about 60 degrees, and the position angle of the central part is horizontal in the figure - in this case the automated orientation function has performed well, though it should never be assumed that this will always be the case!\n",
    "\n",
    "For complete documentation, more usage examples, and further information, please take a look at the [MARTINI webpage](https://martini.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the results (HDF5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the HDF5 that MARTINI produced and take a quick look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File(\"fire_martini_demo.hdf5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the mock cube itself (`f[\"FluxCube\"]`), the HDF5 output contains arrays of the same size with the coordinates of the centre of each cell in the cube in RA, Dec and spectral space (`f[\"RA\"]`,`f[\"Dec\"]` and `f[\"channel_mids\"]`). There are also arrays longer by one in each dimension that contain the coordinates of the corners of each cell in the cube (`f[\"RA_vertices\"]`,`f[\"Dec_vertices\"]` and `f[\"channel_vertices\"]`). The latter are convenient for use with the `pcolormesh` plotting function from matplotlib, so we'll read these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_cube = f[\"FluxCube\"][()] * U.Unit(f[\"FluxCube\"].attrs[\"FluxCubeUnit\"])\n",
    "ra_vertices = f[\"RA_vertices\"][()] * U.Unit(f[\"RA_vertices\"].attrs[\"Unit\"])\n",
    "dec_vertices = f[\"Dec_vertices\"][()] * U.Unit(f[\"RA_vertices\"].attrs[\"Unit\"])\n",
    "spec_vertices = f[\"channel_vertices\"][()] * U.Unit(f[\"channel_vertices\"].attrs[\"Unit\"])\n",
    "vch = (\n",
    "    f[\"velocity_channel_mids\"][()] * U.Unit(f[\"velocity_channel_mids\"].attrs[\"Unit\"])\n",
    "    - source.vsys\n",
    ")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RA range of our cube straddles the RA=0 boundary, let's shift the `ra_vertices` to a (-180, 180] range for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_vertices = np.where(\n",
    "    ra_vertices > 180 * U.deg, ra_vertices - 360 * U.deg, ra_vertices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_cube.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine one of the velocity channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "\n",
    "channel_slice = np.s_[:, :, 15]  # a slice of the data cube containing one channel\n",
    "\n",
    "# choose units for plotting, not necessarily the units data are stored in:\n",
    "ra_unit = U.deg\n",
    "dec_unit = U.deg\n",
    "flux_unit = U.Jy / U.beam\n",
    "\n",
    "plt.pcolormesh(\n",
    "    ra_vertices[channel_slice].to_value(ra_unit),\n",
    "    dec_vertices[channel_slice].to_value(dec_unit),\n",
    "    flux_cube[channel_slice].to_value(flux_unit),\n",
    "    cmap=\"Greys\",\n",
    ")\n",
    "ax.set_xlabel(f\"RA [{ra_unit}]\")\n",
    "ax.set_ylabel(f\"Dec [{dec_unit}]\")\n",
    "ax.set_xlim(ax.get_xlim()[::-1])\n",
    "plt.colorbar(label=f\"Flux [{flux_unit}]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And do a quick plot of the first three moments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# choose units for plotting, not necessarily the units data are stored in:\n",
    "ra_unit = U.deg\n",
    "dec_unit = U.deg\n",
    "mom0_unit = U.Jy / U.beam\n",
    "mom1_unit = U.km / U.s\n",
    "mom2_unit = U.km / U.s\n",
    "\n",
    "np.seterr(all=\"ignore\")\n",
    "fig = plt.figure(figsize=(16, 5))\n",
    "sp1 = fig.add_subplot(1, 3, 1, aspect=\"equal\")\n",
    "sp2 = fig.add_subplot(1, 3, 2, aspect=\"equal\")\n",
    "sp3 = fig.add_subplot(1, 3, 3, aspect=\"equal\")\n",
    "rms = np.std(\n",
    "    flux_cube[:16, :16]\n",
    ")  # noise in a corner patch where there is little signal\n",
    "clip = np.where(flux_cube > 5 * rms, 1, 0)\n",
    "mom0 = np.sum(flux_cube, axis=-1)\n",
    "mask = np.where(mom0 > 0.002 * U.Jy / U.beam, 1, np.nan)\n",
    "mom1 = np.sum(flux_cube * clip * vch, axis=-1) / mom0\n",
    "mom2 = np.sqrt(\n",
    "    np.sum(flux_cube * clip * np.power(vch - mom1[..., np.newaxis], 2), axis=-1) / mom0\n",
    ")\n",
    "im1 = sp1.pcolormesh(\n",
    "    ra_vertices[..., 0].to_value(\n",
    "        ra_unit\n",
    "    ),  # pick one channel, coordinates are the same in all of them\n",
    "    dec_vertices[..., 0].to_value(\n",
    "        dec_unit\n",
    "    ),  # pick one channel, coordinates are the same in all of them\n",
    "    mom0.to_value(mom0_unit),\n",
    "    cmap=\"Greys\",\n",
    ")\n",
    "plt.colorbar(im1, ax=sp1, label=f\"mom0 [{mom0_unit}]\")\n",
    "im2 = sp2.pcolormesh(\n",
    "    ra_vertices[..., 0].to_value(\n",
    "        ra_unit\n",
    "    ),  # pick one channel, coordinates are the same in all of them\n",
    "    dec_vertices[..., 0].to_value(\n",
    "        dec_unit\n",
    "    ),  # pick one channel, coordinates are the same in all of them\n",
    "    (mom1 * mask).to_value(mom1_unit),\n",
    "    cmap=\"RdBu_r\",\n",
    "    vmin=-np.nanmax(np.abs(mom1 * mask)).to_value(mom1_unit),\n",
    "    vmax=np.nanmax(np.abs(mom1 * mask)).to_value(mom1_unit),\n",
    ")\n",
    "plt.colorbar(im2, ax=sp2, label=f\"mom1 [{mom1_unit}]\")\n",
    "im3 = sp3.pcolormesh(\n",
    "    ra_vertices[..., 0].to_value(\n",
    "        ra_unit\n",
    "    ),  # pick one channel, coordinates are the same in all of them\n",
    "    dec_vertices[..., 0].to_value(\n",
    "        dec_unit\n",
    "    ),  # pick one channel, coordinates are the same in all of them\n",
    "    (mom2 * mask).to_value(mom2_unit),\n",
    "    cmap=\"magma\",\n",
    "    vmin=0,\n",
    ")\n",
    "plt.colorbar(im3, ax=sp3, label=f\"mom2 [{mom2_unit}]\")\n",
    "for sp in sp1, sp2, sp3:\n",
    "    sp.set_xlabel(f\"RA [{ra_unit}]\")\n",
    "    sp.set_ylabel(f\"Dec [{dec_unit}]\")\n",
    "    sp.set_xlim(sp.get_xlim()[::-1])\n",
    "plt.subplots_adjust(wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This galaxy has a strongly disturbed morphology, but does display clear signs of rotation. The alignment of the disc, such as it is, looks as expected - the inclination is plausibly about 60 degrees, and the position angle of the central part is horizontal in the figure - in this case the automated orientation function has performed well, though it should never be assumed that this will always be the case!\n",
    "\n",
    "For complete documentation, more usage examples, and further information, please take a look at the [MARTINI webpage](https://martini.readthedocs.io/en/latest/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
